{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfaae28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.3.2 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
      "tensorflow 2.3.2 requires h5py<2.11.0,>=2.10.0, but you have h5py 3.1.0 which is incompatible.\n",
      "tensorflow 2.3.2 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.5 which is incompatible.\n",
      "tensorflow-probability 0.11.0 requires cloudpickle==1.3, but you have cloudpickle 1.6.0 which is incompatible.\u001b[0m\n",
      "TensorFlow Datasets: 4.3.0+nightly\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tf-models-nightly\n",
    "\n",
    "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
    "\n",
    "!pip install -q tfds-nightly\n",
    "!tfds --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c70def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:43: UserWarning: You are currently using a nightly version of TensorFlow (2.6.0-dev20210514). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.platform import flags\n",
    "from tensorflow.python.platform import app\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow_hub as hub\n",
    "from six.moves import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import sys\n",
    "import ast\n",
    "from official.vision.beta.configs import video_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0296cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glosses = [s.split('-')[0] for s in  os.listdir('./data/train')]\n",
    "test_glosses = [s.split('-')[0] for s in  os.listdir('./data/test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7923fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(train_glosses))\n",
    "print(len(test_glosses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81675951",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(np.array(train_glosses + test_glosses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8ee0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beautiful', 'hello', 'please', 'sorry'], dtype='<U9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eba642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd ./data/ && tfds new demo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d937bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO[build.py]: Loading dataset  from path: /home/jupyter/data/demo_dataset/demo_dataset.py\n",
      "INFO[dataset_info.py]: Load dataset info from /home/jupyter/tensorflow_datasets/demo_dataset/1.0.0\n",
      "INFO[build.py]: download_and_prepare for dataset demo_dataset/1.0.0...\n",
      "INFO[native_type_compatibility.py]: Using Any for unsupported type: typing.Sequence[~T]\n",
      "INFO[dataset_builder.py]: Generating dataset demo_dataset (/home/jupyter/tensorflow_datasets/demo_dataset/1.0.0)\n",
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/jupyter/tensorflow_datasets/demo_dataset/1.0.0...\u001b[0m\n",
      "Generating splits...:   0%|                          | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 1 examples [00:00,  2.39 examples/s]\u001b[A\n",
      "Generating train examples...: 2 examples [00:00,  3.69 examples/s]\u001b[A\n",
      "Generating train examples...: 3 examples [00:00,  4.59 examples/s]\u001b[A\n",
      "Generating train examples...: 4 examples [00:00,  5.66 examples/s]\u001b[A\n",
      "Generating train examples...: 5 examples [00:00,  6.47 examples/s]\u001b[A\n",
      "Generating train examples...: 6 examples [00:01,  7.23 examples/s]\u001b[A\n",
      "Generating train examples...: 8 examples [00:01,  8.16 examples/s]\u001b[A\n",
      "Generating train examples...: 9 examples [00:01,  7.95 examples/s]\u001b[A\n",
      "Generating train examples...: 11 examples [00:01,  8.72 examples/s]\u001b[A\n",
      "Generating train examples...: 13 examples [00:01,  9.24 examples/s]\u001b[A\n",
      "Generating train examples...: 14 examples [00:01,  9.38 examples/s]\u001b[A\n",
      "Generating train examples...: 15 examples [00:02,  8.78 examples/s]\u001b[A\n",
      "Generating train examples...: 16 examples [00:02,  7.54 examples/s]\u001b[A\n",
      "Generating train examples...: 18 examples [00:02,  8.06 examples/s]\u001b[A\n",
      "Generating train examples...: 19 examples [00:02,  8.17 examples/s]\u001b[A\n",
      "Generating train examples...: 20 examples [00:02,  7.54 examples/s]\u001b[A\n",
      "Generating train examples...: 22 examples [00:02,  8.98 examples/s]\u001b[A\n",
      "Generating train examples...: 23 examples [00:03,  8.12 examples/s]\u001b[A\n",
      "Generating train examples...: 24 examples [00:03,  8.22 examples/s]\u001b[A\n",
      "Generating train examples...: 25 examples [00:03,  8.57 examples/s]\u001b[A\n",
      "Generating train examples...: 27 examples [00:03,  8.27 examples/s]\u001b[A\n",
      "Generating train examples...: 29 examples [00:03,  8.29 examples/s]\u001b[A\n",
      "Generating train examples...: 30 examples [00:03,  8.46 examples/s]\u001b[A\n",
      "Generating train examples...: 31 examples [00:04,  8.52 examples/s]\u001b[A\n",
      "Generating train examples...: 33 examples [00:04,  9.36 examples/s]\u001b[A\n",
      "Generating train examples...: 34 examples [00:04,  9.34 examples/s]\u001b[A\n",
      "Generating train examples...: 35 examples [00:04,  8.79 examples/s]\u001b[A\n",
      "Generating train examples...: 36 examples [00:04,  7.57 examples/s]\u001b[A\n",
      "Generating train examples...: 37 examples [00:04,  8.06 examples/s]\u001b[A\n",
      "Generating train examples...: 39 examples [00:04,  8.97 examples/s]\u001b[A\n",
      "Generating train examples...: 40 examples [00:05,  8.89 examples/s]\u001b[A\n",
      "Generating train examples...: 42 examples [00:05,  9.36 examples/s]\u001b[A\n",
      "Generating train examples...: 43 examples [00:05,  9.22 examples/s]\u001b[A\n",
      "Generating train examples...: 45 examples [00:05,  9.69 examples/s]\u001b[A\n",
      "Generating train examples...: 46 examples [00:05,  9.70 examples/s]\u001b[A\n",
      "Generating train examples...: 48 examples [00:05, 10.24 examples/s]\u001b[A\n",
      "Generating train examples...: 50 examples [00:05, 10.41 examples/s]\u001b[A\n",
      "Generating train examples...: 52 examples [00:06,  9.47 examples/s]\u001b[A\n",
      "Generating train examples...: 53 examples [00:06,  9.08 examples/s]\u001b[A\n",
      "Generating train examples...: 54 examples [00:06,  7.67 examples/s]\u001b[A\n",
      "Generating train examples...: 55 examples [00:06,  7.26 examples/s]\u001b[A\n",
      "Generating train examples...: 56 examples [00:06,  7.58 examples/s]\u001b[A\n",
      "                                                                   \u001b[A\n",
      "Shuffling demo_dataset-train.tfrecord...:   0%|   | 0/56 [00:00<?, ? examples/s]\u001b[A\n",
      "INFO[tfrecords_writer.py]: Done writing demo_dataset-train.tfrecord. Number of examples: 56 (shards: [56])\n",
      "Generating splits...:  50%|█████████         | 1/2 [00:06<00:06,  6.95s/ splits]\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 1 examples [00:00,  8.47 examples/s]\u001b[A\n",
      "Generating test examples...: 2 examples [00:00,  5.83 examples/s]\u001b[A\n",
      "Generating test examples...: 3 examples [00:00,  5.96 examples/s]\u001b[A\n",
      "Generating test examples...: 5 examples [00:00,  8.32 examples/s]\u001b[A\n",
      "Generating test examples...: 7 examples [00:00,  9.47 examples/s]\u001b[A\n",
      "Generating test examples...: 8 examples [00:00,  8.85 examples/s]\u001b[A\n",
      "Generating test examples...: 9 examples [00:01,  9.10 examples/s]\u001b[A\n",
      "Generating test examples...: 10 examples [00:01,  8.51 examples/s]\u001b[A\n",
      "Generating test examples...: 11 examples [00:01,  6.88 examples/s]\u001b[A\n",
      "Generating test examples...: 12 examples [00:01,  7.37 examples/s]\u001b[A\n",
      "Generating test examples...: 14 examples [00:01,  8.40 examples/s]\u001b[A\n",
      "Generating test examples...: 15 examples [00:01,  8.16 examples/s]\u001b[A\n",
      "Generating test examples...: 16 examples [00:01,  8.36 examples/s]\u001b[A\n",
      "Generating test examples...: 18 examples [00:02,  7.89 examples/s]\u001b[A\n",
      "Generating test examples...: 19 examples [00:02,  7.78 examples/s]\u001b[A\n",
      "Generating test examples...: 21 examples [00:02,  8.67 examples/s]\u001b[A\n",
      "Generating test examples...: 23 examples [00:02,  9.95 examples/s]\u001b[A\n",
      "Generating test examples...: 25 examples [00:02, 10.83 examples/s]\u001b[A\n",
      "                                                                  \u001b[A\n",
      "Shuffling demo_dataset-test.tfrecord...:   0%|    | 0/25 [00:00<?, ? examples/s]\u001b[A\n",
      "INFO[tfrecords_writer.py]: Done writing demo_dataset-test.tfrecord. Number of examples: 25 (shards: [25])\n",
      "\u001b[1mDataset demo_dataset downloaded and prepared to /home/jupyter/tensorflow_datasets/demo_dataset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "INFO[build.py]: Dataset generation complete...\n",
      "\n",
      "tfds.core.DatasetInfo(\n",
      "    name='demo_dataset',\n",
      "    full_name='demo_dataset/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Description is **formatted** as markdown.\n",
      "    \n",
      "    It should also contain any processing which has been applied (if any),\n",
      "    (e.g. corrupted example skipped, images cropped,...):\n",
      "    \"\"\",\n",
      "    homepage='https://dataset-homepage/',\n",
      "    data_path='/home/jupyter/tensorflow_datasets/demo_dataset/1.0.0',\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=40.92 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
      "        'video': Video(Image(shape=(224, 224, 3), dtype=tf.uint8)),\n",
      "    }),\n",
      "    supervised_keys=('video', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=25, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=56, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"Description is **formatted** as markdown.\n",
      "    \n",
      "    It should also contain any processing which has been applied (if any),\n",
      "    (e.g. corrupted example skipped, images cropped,...):\"\"\",\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd ./data/demo_dataset/ && tfds build --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0671207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'demo_dataset'\n",
    "\n",
    "builder = tfds.builder(dataset_name)\n",
    "num_classes = builder.info.features['label'].num_classes\n",
    "num_examples = {\n",
    "    name: split.num_examples\n",
    "    for name, split in builder.info.splits.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c87e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_frames = 8\n",
    "frame_stride = 10\n",
    "resolution = 224\n",
    "\n",
    "def format_features(features):\n",
    "  video = features['video']\n",
    "  video = video[:, ::frame_stride]\n",
    "  video = video[:, :num_frames]\n",
    "  \n",
    "  video = tf.reshape(video, [-1, video.shape[2], video.shape[3], 3])\n",
    "  video = tf.image.resize(video, (resolution, resolution))\n",
    "  video = tf.reshape(video, [-1, num_frames, resolution, resolution, 3])\n",
    "  video = tf.cast(video, tf.float32) / 255.\n",
    "\n",
    "  label = tf.one_hot(features['label'], num_classes)\n",
    "  return (video, label)\n",
    "\n",
    "train_dataset = builder.as_dataset(\n",
    "    split='train',\n",
    "    batch_size=batch_size,\n",
    "    shuffle_files=True)\n",
    "train_dataset = train_dataset.map(\n",
    "    format_features,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(2)\n",
    "\n",
    "test_dataset = builder.as_dataset(\n",
    "    split='test',\n",
    "    batch_size=batch_size)\n",
    "test_dataset = test_dataset.map(\n",
    "    format_features,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=True)\n",
    "test_dataset = test_dataset.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1c9be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, './model')\n",
    "\n",
    "import movinet\n",
    "import movinet_model\n",
    "import movinet_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56dd0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TFHUB_CACHE_DIR'] = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'a2'\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "backbone = movinet.Movinet(\n",
    "    model_id=model_id,\n",
    "    stochastic_depth_drop_rate=0.)\n",
    "model = movinet_model.MovinetClassifier(\n",
    "    backbone=backbone,\n",
    "    num_classes=600,\n",
    "    dropout_rate=0.)\n",
    "model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "# Load pretrained weights from TF Hub\n",
    "movinet_hub_url = f'https://tfhub.dev/tensorflow/movinet/{model_id}/base/kinetics-600/classification/1'\n",
    "movinet_hub_model = hub.KerasLayer(movinet_hub_url, trainable=True)\n",
    "pretrained_weights = {w.name: w for w in movinet_hub_model.weights}\n",
    "model_weights = {w.name: w for w in model.weights}\n",
    "for name in pretrained_weights:\n",
    "  model_weights[name].assign(pretrained_weights[name])\n",
    "\n",
    "# Wrap the backbone with a new classifier to create a new classifier head\n",
    "# with num_classes outputs\n",
    "model = movinet_model.MovinetClassifier(\n",
    "    backbone=backbone,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "# Freeze all layers except for the final classifier head\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "model.layers[-1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fc0060d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movinet_classifier_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "states/image (InputLayer)    [(None, None, None, None, 0         \n",
      "_________________________________________________________________\n",
      "movinet (Movinet)            ({'stem': (None, None, No 2738754   \n",
      "_________________________________________________________________\n",
      "classifier_head_1 (Classifie (None, 4)                 1320964   \n",
      "=================================================================\n",
      "Total params: 4,059,718\n",
      "Trainable params: 1,320,964\n",
      "Non-trainable params: 2,738,754\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89cd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "train_steps = num_examples['train'] // batch_size\n",
    "total_train_steps = train_steps * num_epochs\n",
    "test_steps = num_examples['test'] // batch_size\n",
    "\n",
    "loss_obj = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    label_smoothing=0.1)\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TopKCategoricalAccuracy(\n",
    "        k=1, name='top_1', dtype=tf.float32),\n",
    "    tf.keras.metrics.TopKCategoricalAccuracy(\n",
    "        k=5, name='top_5', dtype=tf.float32),\n",
    "]\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=total_train_steps, decay_rate=0.96\n",
    ")\n",
    "optimizer = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate, rho=0.9, momentum=0.9, epsilon=1.0, clipnorm=1.0)\n",
    "\n",
    "model.compile(loss=loss_obj, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "851075db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "def get_config(self):\n",
    "    config = {\n",
    "        'backbone': self._backbone,\n",
    "        'num_classes': self._num_classes,\n",
    "        'input_specs': self._input_specs,\n",
    "        'dropout_rate': self._dropout_rate,\n",
    "        'kernel_initializer': self._kernel_initializer,\n",
    "        'kernel_regularizer': self._kernel_regularizer,\n",
    "        'bias_regularizer': self._bias_regularizer,\n",
    "        'output_states': self._output_states,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "model.get_config = MethodType(get_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e8ac5c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movinet_classifier_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "states/image (InputLayer)    [(None, None, None, None, 0         \n",
      "_________________________________________________________________\n",
      "movinet (Movinet)            ({'stem': (None, None, No 2738754   \n",
      "_________________________________________________________________\n",
      "classifier_head_1 (Classifie (None, 4)                 1320964   \n",
      "=================================================================\n",
      "Total params: 4,059,718\n",
      "Trainable params: 1,320,964\n",
      "Non-trainable params: 2,738,754\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d2e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/7 [====================>.........] - ETA: 9:12 - loss: 1.2567 - top_1: 0.6000 - top_5: 1.0000 "
     ]
    }
   ],
   "source": [
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=test_steps,\n",
    "    callbacks=callbacks,\n",
    "    validation_freq=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76c66472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0599c2bd90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0599c2bd90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <official.vision.beta.modeling.layers.nn_layers.TemporalSoftmaxPool object at 0x7f05ed12c790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <official.vision.beta.modeling.layers.nn_layers.TemporalSoftmaxPool object at 0x7f05ed12c790>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as head_layer_call_fn, head_layer_call_and_return_conditional_losses, classifier_layer_call_fn, classifier_layer_call_and_return_conditional_losses, squeeze3d_1_layer_call_fn while saving (showing 5 of 2600). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadata field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadata field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/trained_model/7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/trained_model/7/assets\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def serving(video_tensor):\n",
    "    payload = {\n",
    "      'image': video_tensor,\n",
    "    }\n",
    "    predictions = model(payload)\n",
    "    return predictions\n",
    "\n",
    "serving = serving.get_concrete_function(video_tensor=tf.TensorSpec([1, 5, 224, 224, 3], dtype= tf.float32, name='image'))\n",
    "\n",
    "tf.saved_model.save(\n",
    "  model,\n",
    "  './model/trained_model/7',\n",
    "  signatures=serving\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load('./model/trained_models/6')\n",
    "f = imported.signatures[\"serving_default\"]\n",
    "arr = convert_video_to_numpy(\n",
    "                filenames = ['./data/serving/video.mp4'], \n",
    "                n_frames_per_video = 5, \n",
    "                width = 224, \n",
    "                height = 224,\n",
    "                n_channels = 3,\n",
    "                dense_optical_flow=False)[0]\n",
    "\n",
    "arr = np.true_divide(arr, 255)\n",
    "print(arr)\n",
    "# print(tf.convert_to_tensor(arr, dtype=tf.float32))\n",
    "pred = f(\n",
    "    image=tf.reshape(\n",
    "    tensor=tf.convert_to_tensor(arr, dtype=tf.float32),\n",
    "    shape=(1, 5, 224, 224, 3)))\n",
    "\n",
    "print(pred)\n",
    "layer = tf.keras.layers.Softmax()\n",
    "layer(pred['output_0']).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fe719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
